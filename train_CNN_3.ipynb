{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet_18_fcn import *\n",
    "from resnet_34_fcn import *\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "# Initialize Weights with Xavier Weight Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:  # Check if the bias exists\n",
    "            torch.nn.init.normal_(m.bias.data)  # Xavier not applicable for biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "750ceef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_ResNet34(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset =voc.VOC('train', transform=input_transform, target_transform=target_transform)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 16, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "n_class = 21\n",
    "\n",
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ad2ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-4)\n",
    "\n",
    "# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fcn_model = fcn_model.to(device)\n",
    "max_model = fcn_model\n",
    "\n",
    "earlystop = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5198b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            #if iter % 10 == 0:\n",
    "            #    print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "\n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        # Save current IoU if better than stored best\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model) # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode. DONE\n",
    "    - Disable gradient calculations. DONE\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Validation Set\n",
    "        for iter, (input, label) in enumerate(val_loader):\n",
    "            # label = (16, 224, 224) / batch size 16 of 244*244 masks\n",
    "            # output = (16, 21, 224, 224) / batch size 16 of 21 possible classes of 244*244 masks\n",
    "            \n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "            \n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    print(f\"Validation Loss: {np.mean(losses)}\")\n",
    "    print(f\"Validation IoU: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Validation Pixel Acc: {np.mean(accuracy)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "def modelTest():\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model = copy.deepcopy(max_model) # Asssume model loaded with the best weights.\n",
    "    \n",
    "    fcn_model.eval()  # Put in eval mode (disables batchnorm/dropout) !\n",
    "\n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad():  # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Test Set\n",
    "        for iter, (input, label) in enumerate(test_loader):\n",
    "\n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    print(f\"Test Loss at Test: {np.mean(losses)}\")\n",
    "    print(f\"Test IoU at Test: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Test Pixel acc at Test: {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = fcn_model(inputs)\n",
    "    \n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     val(0)  # show the accuracy before training\n",
    "#     train()\n",
    "#     modelTest()\n",
    "\n",
    "#     # housekeeping\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05d0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 21.06040668487549\n",
      "Train Avg Loss: 2.89590162890298\n",
      "Validation Loss: 2.5461331946509227\n",
      "Validation IoU: 0.00132408230750982\n",
      "Validation Pixel Acc: 0.01300769505625911\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 17.316808700561523\n",
      "Train Avg Loss: 2.8260586857795715\n",
      "Validation Loss: 2.5046353340148926\n",
      "Validation IoU: 0.003329347376031725\n",
      "Validation Pixel Acc: 0.03693920613725401\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 17.39508080482483\n",
      "Train Avg Loss: 2.7753842785244895\n",
      "Validation Loss: 2.4603898525238037\n",
      "Validation IoU: 0.016166048771360197\n",
      "Validation Pixel Acc: 0.18590826362632104\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 20.31821846961975\n",
      "Train Avg Loss: 2.739593484572002\n",
      "Validation Loss: 2.342496361051287\n",
      "Validation IoU: 0.04246616804681991\n",
      "Validation Pixel Acc: 0.6280745703694425\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 21.62053680419922\n",
      "Train Avg Loss: 2.7002184765679496\n",
      "Validation Loss: 2.962302259036473\n",
      "Validation IoU: 0.025361407756756833\n",
      "Validation Pixel Acc: 0.4230834427102314\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 28.613245248794556\n",
      "Train Avg Loss: 2.6677834334827604\n",
      "Validation Loss: 2.7338368041174754\n",
      "Validation IoU: 0.017726062422424253\n",
      "Validation Pixel Acc: 0.27389387570039175\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 26.74483060836792\n",
      "Train Avg Loss: 2.63692222809305\n",
      "Validation Loss: 2.59335948739733\n",
      "Validation IoU: 0.03742386626807378\n",
      "Validation Pixel Acc: 0.6591024415486061\n",
      "\n",
      "\n",
      "Early stop at epoch 6\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2052aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 2.6380134310041154\n",
      "Test IoU at Test: 0.04158568968972791\n",
      "Test Pixel acc at Test: 0.6266295319048378\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4f946",
   "metadata": {},
   "source": [
    "## Q4.a COSINE ANNEALING LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5df8cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a76e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1():\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            scheduler.step() # For cosine annealing learning rate\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "        \n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model)\n",
    "            # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "#         if patience >= earlystop:\n",
    "#             print(\"Early stop at epoch \" + str(epoch))\n",
    "#             break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6675c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 4.617120027542114\n",
      "Train Avg Loss: 4.197633164269583\n",
      "Validation Loss: 3.8772651297705516\n",
      "Validation IoU: 0.0003656049594933903\n",
      "Validation Pixel Acc: 0.00207813140602223\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 4.583094835281372\n",
      "Train Avg Loss: 4.062610472951617\n",
      "Validation Loss: 3.7255057096481323\n",
      "Validation IoU: 0.0001291393948011038\n",
      "Validation Pixel Acc: 0.001965848071929665\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 4.380997657775879\n",
      "Train Avg Loss: 3.98191351549966\n",
      "Validation Loss: 3.577138696398054\n",
      "Validation IoU: 0.00012911886267857073\n",
      "Validation Pixel Acc: 0.001965581154336735\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 4.323671579360962\n",
      "Train Avg Loss: 3.8732859066554477\n",
      "Validation Loss: 3.5634100266865323\n",
      "Validation IoU: 0.0003793546633420247\n",
      "Validation Pixel Acc: 0.00201416015625\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 4.081014394760132\n",
      "Train Avg Loss: 3.790125318935939\n",
      "Validation Loss: 3.5263048240116666\n",
      "Validation IoU: 0.001283863158040488\n",
      "Validation Pixel Acc: 0.0046394370387664\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 3.5410778522491455\n",
      "Train Avg Loss: 3.7024430206843784\n",
      "Validation Loss: 3.16657669203622\n",
      "Validation IoU: 0.01250551456019652\n",
      "Validation Pixel Acc: 0.17272669845002733\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.432241201400757\n",
      "Train Avg Loss: 3.55961275100708\n",
      "Validation Loss: 3.4417420285088673\n",
      "Validation IoU: 0.029964072928936623\n",
      "Validation Pixel Acc: 0.44728222727428024\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.292583703994751\n",
      "Train Avg Loss: 3.479915499687195\n",
      "Validation Loss: 3.3021897077560425\n",
      "Validation IoU: 0.034258966917529825\n",
      "Validation Pixel Acc: 0.4983826395373998\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.1324944496154785\n",
      "Train Avg Loss: 3.389601843697684\n",
      "Validation Loss: 3.061345338821411\n",
      "Validation IoU: 0.023332761593523654\n",
      "Validation Pixel Acc: 0.33059009073774603\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.220425605773926\n",
      "Train Avg Loss: 3.3110767092023576\n",
      "Validation Loss: 2.823767134121486\n",
      "Validation IoU: 0.03552048122898801\n",
      "Validation Pixel Acc: 0.600161787650328\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.3461968898773193\n",
      "Train Avg Loss: 3.2310601813452586\n",
      "Validation Loss: 3.473433715956552\n",
      "Validation IoU: 0.031919213373053826\n",
      "Validation Pixel Acc: 0.4935590115650054\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 2.938056707382202\n",
      "Train Avg Loss: 3.132097704069955\n",
      "Validation Loss: 3.1852521555764333\n",
      "Validation IoU: 0.035178939685218076\n",
      "Validation Pixel Acc: 0.5807234071781614\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 2.989245891571045\n",
      "Train Avg Loss: 3.0313709122794017\n",
      "Validation Loss: 3.37945488521031\n",
      "Validation IoU: 0.037508878649234044\n",
      "Validation Pixel Acc: 0.6486271894360421\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 2.9766764640808105\n",
      "Train Avg Loss: 2.9228806495666504\n",
      "Validation Loss: 2.761039912700653\n",
      "Validation IoU: 0.03563827882262518\n",
      "Validation Pixel Acc: 0.6249162056703262\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 3.2274158000946045\n",
      "Train Avg Loss: 2.8618953909192766\n",
      "Validation Loss: 2.7162898438317433\n",
      "Validation IoU: 0.038575862032441864\n",
      "Validation Pixel Acc: 0.687970967195472\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 3.1649630069732666\n",
      "Train Avg Loss: 2.7205125944955006\n",
      "Validation Loss: 2.4495158195495605\n",
      "Validation IoU: 0.040686927861496074\n",
      "Validation Pixel Acc: 0.6898187665133018\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 3.3160240650177\n",
      "Train Avg Loss: 2.645955664770944\n",
      "Validation Loss: 5.328334365572248\n",
      "Validation IoU: 0.036202508170636236\n",
      "Validation Pixel Acc: 0.674389933149599\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 3.138676166534424\n",
      "Train Avg Loss: 2.728044271469116\n",
      "Validation Loss: 2.453349913869585\n",
      "Validation IoU: 0.04152520955916792\n",
      "Validation Pixel Acc: 0.7003390743155521\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 3.038933515548706\n",
      "Train Avg Loss: 2.493261558668954\n",
      "Validation Loss: 3.6192838634763445\n",
      "Validation IoU: 0.0380369361505829\n",
      "Validation Pixel Acc: 0.7097868716403972\n",
      "\n",
      "\n",
      "Finish epoch 19, time elapsed 3.490577220916748\n",
      "Train Avg Loss: 2.3452689817973544\n",
      "Validation Loss: 2.2092593227113997\n",
      "Validation IoU: 0.03986176465723251\n",
      "Validation Pixel Acc: 0.7153218349979501\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df41db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 3.3685128007616316\n",
      "Test IoU at Test: 0.039544193085749406\n",
      "Test Pixel acc at Test: 0.5856814370558491\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e511b76",
   "metadata": {},
   "source": [
    "## Q4.b Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f97876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61c44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.117100238800049\n",
      "Train Avg Loss: 3.2413190603256226\n",
      "Validation Loss: 3.3104273762021745\n",
      "Validation IoU: 0.0005423732197926635\n",
      "Validation Pixel Acc: 0.008012421277104591\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.042057514190674\n",
      "Train Avg Loss: 3.18077746459416\n",
      "Validation Loss: 2.7423292228153775\n",
      "Validation IoU: 0.0005460681219005091\n",
      "Validation Pixel Acc: 0.00806491507038083\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.0474495887756348\n",
      "Train Avg Loss: 3.1124085301444646\n",
      "Validation Loss: 2.6109058686665128\n",
      "Validation IoU: 0.0062793098441153395\n",
      "Validation Pixel Acc: 0.07164415187112792\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 3.0640385150909424\n",
      "Train Avg Loss: 3.0645368780408586\n",
      "Validation Loss: 2.8934601034436906\n",
      "Validation IoU: 0.010576875472371386\n",
      "Validation Pixel Acc: 0.12947978472918184\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.0904598236083984\n",
      "Train Avg Loss: 3.02535457611084\n",
      "Validation Loss: 3.6116258927753995\n",
      "Validation IoU: 0.021616062753321015\n",
      "Validation Pixel Acc: 0.2912935395977588\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 2.828112840652466\n",
      "Train Avg Loss: 2.9860361104919795\n",
      "Validation Loss: 2.6791415895734514\n",
      "Validation IoU: 0.03683056300394879\n",
      "Validation Pixel Acc: 0.5528438468021137\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.107306480407715\n",
      "Train Avg Loss: 2.946641595996156\n",
      "Validation Loss: 2.9193587814058577\n",
      "Validation IoU: 0.039457844462142386\n",
      "Validation Pixel Acc: 0.6191533658664358\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 2.930865526199341\n",
      "Train Avg Loss: 2.909115882856505\n",
      "Validation Loss: 2.8625032901763916\n",
      "Validation IoU: 0.038647317413520774\n",
      "Validation Pixel Acc: 0.6553935682113247\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 2.9667365550994873\n",
      "Train Avg Loss: 2.8679622657715327\n",
      "Validation Loss: 2.607723491532462\n",
      "Validation IoU: 0.04141837291315192\n",
      "Validation Pixel Acc: 0.6717241915599945\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.049082040786743\n",
      "Train Avg Loss: 2.821672705241612\n",
      "Validation Loss: 2.651245449270521\n",
      "Validation IoU: 0.04225160094053626\n",
      "Validation Pixel Acc: 0.6888756754794552\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.0307462215423584\n",
      "Train Avg Loss: 2.785642481469489\n",
      "Validation Loss: 3.4266499195780074\n",
      "Validation IoU: 0.04108988876912736\n",
      "Validation Pixel Acc: 0.6826632752710459\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 3.125967025756836\n",
      "Train Avg Loss: 2.752364089091619\n",
      "Validation Loss: 3.243663098130907\n",
      "Validation IoU: 0.04248831788552492\n",
      "Validation Pixel Acc: 0.7072463144018768\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 3.1509411334991455\n",
      "Train Avg Loss: 2.7156805324030446\n",
      "Validation Loss: 2.1088427220072066\n",
      "Validation IoU: 0.04236670003138492\n",
      "Validation Pixel Acc: 0.7222402144451532\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 2.8986899852752686\n",
      "Train Avg Loss: 2.6753963104316165\n",
      "Validation Loss: 2.125916293689183\n",
      "Validation IoU: 0.04267746853054001\n",
      "Validation Pixel Acc: 0.7182795488452077\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 2.9979867935180664\n",
      "Train Avg Loss: 2.637098855064029\n",
      "Validation Loss: 2.1979738644191196\n",
      "Validation IoU: 0.04221892559920194\n",
      "Validation Pixel Acc: 0.7333454810495627\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 3.1205241680145264\n",
      "Train Avg Loss: 2.5942715587360516\n",
      "Validation Loss: 2.0218480059078763\n",
      "Validation IoU: 0.04430067568541485\n",
      "Validation Pixel Acc: 0.733522785509293\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 3.1243531703948975\n",
      "Train Avg Loss: 2.5523556425791827\n",
      "Validation Loss: 2.4586283564567566\n",
      "Validation IoU: 0.043745691325471396\n",
      "Validation Pixel Acc: 0.7272968792706817\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 3.2091352939605713\n",
      "Train Avg Loss: 2.511462951463366\n",
      "Validation Loss: 2.1960382972444807\n",
      "Validation IoU: 0.04330143534819218\n",
      "Validation Pixel Acc: 0.7273015236367985\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 3.2747018337249756\n",
      "Train Avg Loss: 2.470023550037155\n",
      "Validation Loss: 1.9149992636271886\n",
      "Validation IoU: 0.041293073378037816\n",
      "Validation Pixel Acc: 0.7359515220708818\n",
      "\n",
      "\n",
      "Early stop at epoch 18\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f9f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.856745915753501\n",
      "Test IoU at Test: 0.04361906536443096\n",
      "Test Pixel acc at Test: 0.7138462789552206\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673b97d",
   "metadata": {},
   "source": [
    "## Q4.c Weight Imbalance + (Image Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a945981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights():\n",
    "    ans = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # Iterate through the training set\n",
    "    for iter, (inputs, labels) in enumerate(train_loader):  \n",
    "        unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "        # Count number of each class\n",
    "        for i in range(len(unique_elements)):\n",
    "            ans[unique_elements[i]] += counts[i]\n",
    "\n",
    "    normalized = [tensor.tolist() for tensor in ans]\n",
    "    #normalized = [num/sum(normalized) for num in normalized]\n",
    "    normalized = [1/(1-pow(0.1,num/50000)) for num in normalized]\n",
    "    return torch.tensor(normalized)\n",
    "#     class_counts = [0] * 21  # Assuming 21 classes\n",
    "    \n",
    "#     # Iterate through the training set\n",
    "#     for _, labels in train_loader:\n",
    "#         labels = labels.view(-1)  # Flatten labels tensor to 1D, if necessary\n",
    "#         unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "#         # Ensure unique_elements is a tensor of integers for indexing\n",
    "#         unique_elements = unique_elements.to(torch.int64)\n",
    "        \n",
    "#         # Update counts for each class\n",
    "#         for i in range(len(unique_elements)):\n",
    "#             element = unique_elements[i].item()  # Convert to Python int\n",
    "#             count = counts[i].item()\n",
    "#             if element < len(class_counts):  # Check is now valid\n",
    "#                 class_counts[element] += count\n",
    "    \n",
    "#     # Avoid division by zero for classes not present in the dataset\n",
    "#     class_counts = [max(count, 1) for count in class_counts]\n",
    "\n",
    "#     # Calculate weights inversely proportional to class frequencies\n",
    "#     total_count = sum(class_counts)\n",
    "#     weights = [total_count / count for count in class_counts]\n",
    "    \n",
    "#     # Normalize weights (optional)\n",
    "#     min_weight = min(weights)\n",
    "#     normalized_weights = [weight / min_weight for weight in weights]\n",
    "\n",
    "#     return torch.tensor(normalized_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70afee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.1216, 1.1607, 1.0169, 1.1303, 1.0409, 1.0001, 1.0333, 1.0002,\n",
      "        1.0060, 1.0280, 1.0024, 1.0013, 1.0198, 1.0270, 1.0000, 1.3043, 1.5267,\n",
      "        1.0005, 1.0040, 1.0025])\n"
     ]
    }
   ],
   "source": [
    "class_weights = getClassWeights()\n",
    "print(class_weights)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 5\n",
    "max_model = fcn_model\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-1)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "# T_max = 10\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_max, T_mult=1, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86fdada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.3205885887145996\n",
      "Train Avg Loss: 2.013990342617035\n",
      "Validation Loss: 1.9089797309466772\n",
      "Validation IoU: 0.05085004890565888\n",
      "Validation Pixel Acc: 0.7375907697761024\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.2036216259002686\n",
      "Train Avg Loss: 1.3851521100316728\n",
      "Validation Loss: 1.518652183668954\n",
      "Validation IoU: 0.05383695172653363\n",
      "Validation Pixel Acc: 0.7294901411317876\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.0787460803985596\n",
      "Train Avg Loss: 1.3215112345559257\n",
      "Validation Loss: 1.3880389290196555\n",
      "Validation IoU: 0.05573232070334965\n",
      "Validation Pixel Acc: 0.7517313342747813\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 2.9081571102142334\n",
      "Train Avg Loss: 1.3224413565226965\n",
      "Validation Loss: 1.33985350387437\n",
      "Validation IoU: 0.05435184846332752\n",
      "Validation Pixel Acc: 0.7519261307341016\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.3318681716918945\n",
      "Train Avg Loss: 1.2865652697426933\n",
      "Validation Loss: 1.3327766060829163\n",
      "Validation IoU: 0.052261375346117925\n",
      "Validation Pixel Acc: 0.7513819035566236\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 2.949505567550659\n",
      "Train Avg Loss: 1.2569679703031267\n",
      "Validation Loss: 1.3822561715330397\n",
      "Validation IoU: 0.053975530229476446\n",
      "Validation Pixel Acc: 0.7516421837987427\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.017087936401367\n",
      "Train Avg Loss: 1.2172712194068092\n",
      "Validation Loss: 1.3354331425258092\n",
      "Validation IoU: 0.051273542906579005\n",
      "Validation Pixel Acc: 0.7511287767059949\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.089853048324585\n",
      "Train Avg Loss: 1.2209653386047907\n",
      "Validation Loss: 1.3172708281448908\n",
      "Validation IoU: 0.05271837923372367\n",
      "Validation Pixel Acc: 0.7510009409734877\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.0720458030700684\n",
      "Train Avg Loss: 1.277557373046875\n",
      "Validation Loss: 1.3471118424619948\n",
      "Validation IoU: 0.052233645497065447\n",
      "Validation Pixel Acc: 0.7501271951302844\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 2.9841887950897217\n",
      "Train Avg Loss: 1.4657281807490758\n",
      "Validation Loss: 1.3424586653709412\n",
      "Validation IoU: 0.05406679871415015\n",
      "Validation Pixel Acc: 0.7491312722075437\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 2.779294729232788\n",
      "Train Avg Loss: 1.5057480505534582\n",
      "Validation Loss: 1.3708838735307967\n",
      "Validation IoU: 0.050910207693065694\n",
      "Validation Pixel Acc: 0.7480263401398505\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 2.9686570167541504\n",
      "Train Avg Loss: 1.3080575934478216\n",
      "Validation Loss: 1.363575850214277\n",
      "Validation IoU: 0.05239149266017316\n",
      "Validation Pixel Acc: 0.7509531983133656\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 2.986821413040161\n",
      "Train Avg Loss: 1.249682456254959\n",
      "Validation Loss: 1.4246289389474052\n",
      "Validation IoU: 0.05373667408060028\n",
      "Validation Pixel Acc: 0.75156979574754\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 2.9990642070770264\n",
      "Train Avg Loss: 1.3269012059484209\n",
      "Validation Loss: 1.3516410206045424\n",
      "Validation IoU: 0.052323054015164454\n",
      "Validation Pixel Acc: 0.7509273962793822\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 3.400300979614258\n",
      "Train Avg Loss: 1.5613679587841034\n",
      "Validation Loss: 1.4165567925998144\n",
      "Validation IoU: 0.0519990751817043\n",
      "Validation Pixel Acc: 0.7503419570255557\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 3.343172073364258\n",
      "Train Avg Loss: 1.339404889515468\n",
      "Validation Loss: 1.3958116471767426\n",
      "Validation IoU: 0.050582641037745554\n",
      "Validation Pixel Acc: 0.7472366377494077\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 2.7926156520843506\n",
      "Train Avg Loss: 1.249112925359181\n",
      "Validation Loss: 1.3535757490566798\n",
      "Validation IoU: 0.052013761075476825\n",
      "Validation Pixel Acc: 0.7476701297148324\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 2.9022796154022217\n",
      "Train Avg Loss: 1.221754035779408\n",
      "Validation Loss: 1.3024002824510847\n",
      "Validation IoU: 0.05336442363125953\n",
      "Validation Pixel Acc: 0.7501518405213646\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 3.1299996376037598\n",
      "Train Avg Loss: 1.1954649346215385\n",
      "Validation Loss: 1.4017079387392317\n",
      "Validation IoU: 0.05308962654819085\n",
      "Validation Pixel Acc: 0.7457005270020954\n",
      "\n",
      "\n",
      "Finish epoch 19, time elapsed 3.0668129920959473\n",
      "Train Avg Loss: 1.2447595681462968\n",
      "Validation Loss: 1.3076160933290208\n",
      "Validation IoU: 0.05286780157580923\n",
      "Validation Pixel Acc: 0.7499663149997724\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14daff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.3940854242869787\n",
      "Test IoU at Test: 0.05322990909617587\n",
      "Test Pixel acc at Test: 0.7246881156899143\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79be37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
