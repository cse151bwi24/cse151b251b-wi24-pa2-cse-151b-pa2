{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet_18_fcn import *\n",
    "from resnet_34_fcn import *\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "# Initialize Weights with Xavier Weight Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.normal_(m.bias.data) #xavier not applicable for biases\n",
    "        if m.bias is not None:  # Check if the bias exists\n",
    "            torch.nn.init.normal_(m.bias.data)  # Xavier not applicable for biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750ceef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hejin\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\hejin\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m n_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m\n\u001b[0;32m     19\u001b[0m fcn_model \u001b[38;5;241m=\u001b[39m FCN_ResNet34(n_class\u001b[38;5;241m=\u001b[39mn_class)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mfcn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:890\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:890\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    887\u001b[0m \n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:891\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    890\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 891\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 23\u001b[0m, in \u001b[0;36minit_weights\u001b[1;34m(m)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mConv2d) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mConvTranspose2d):\n\u001b[0;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m---> 23\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mnormal_(\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset =voc.VOC('train', transform=input_transform, target_transform=target_transform)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 16, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "n_class = 21\n",
    "\n",
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad2ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-4)\n",
    "\n",
    "# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fcn_model = fcn_model.to(device)\n",
    "max_model = fcn_model\n",
    "\n",
    "earlystop = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5198b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            #if iter % 10 == 0:\n",
    "            #    print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "\n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        # Save current IoU if better than stored best\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model) # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode. DONE\n",
    "    - Disable gradient calculations. DONE\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Validation Set\n",
    "        for iter, (input, label) in enumerate(val_loader):\n",
    "            # label = (16, 224, 224) / batch size 16 of 244*244 masks\n",
    "            # output = (16, 21, 224, 224) / batch size 16 of 21 possible classes of 244*244 masks\n",
    "            \n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "            \n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    print(f\"Validation Loss: {np.mean(losses)}\")\n",
    "    print(f\"Validation IoU: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Validation Pixel Acc: {np.mean(accuracy)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "def modelTest():\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model = copy.deepcopy(max_model) # Asssume model loaded with the best weights.\n",
    "    \n",
    "    fcn_model.eval()  # Put in eval mode (disables batchnorm/dropout) !\n",
    "\n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad():  # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Test Set\n",
    "        for iter, (input, label) in enumerate(test_loader):\n",
    "\n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    print(f\"Test Loss at Test: {np.mean(losses)}\")\n",
    "    print(f\"Test IoU at Test: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Test Pixel acc at Test: {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = fcn_model(inputs)\n",
    "    \n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     val(0)  # show the accuracy before training\n",
    "#     train()\n",
    "#     modelTest()\n",
    "\n",
    "#     # housekeeping\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b05d0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 10.932702541351318\n",
      "Train Avg Loss: 2.2333646757262096\n",
      "Validation Loss: 1.4381170315401894\n",
      "Validation IoU: 0.053691666031312806\n",
      "Validation Pixel Acc: 0.7392254264987247\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 10.668454885482788\n",
      "Train Avg Loss: 1.7796936631202698\n",
      "Validation Loss: 1.3433957993984222\n",
      "Validation IoU: 0.05372888506981775\n",
      "Validation Pixel Acc: 0.7397263062591107\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 10.195504665374756\n",
      "Train Avg Loss: 1.5972679158051808\n",
      "Validation Loss: 1.4163699405533927\n",
      "Validation IoU: 0.05564781345682834\n",
      "Validation Pixel Acc: 0.7508232094456085\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 10.672451972961426\n",
      "Train Avg Loss: 1.5055835034166063\n",
      "Validation Loss: 1.2982743297304427\n",
      "Validation IoU: 0.05564781345682834\n",
      "Validation Pixel Acc: 0.7508232094456085\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 10.23966932296753\n",
      "Train Avg Loss: 1.4469209160123553\n",
      "Validation Loss: 1.2275715725762504\n",
      "Validation IoU: 0.05564781345682834\n",
      "Validation Pixel Acc: 0.7508232094456085\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 10.223397254943848\n",
      "Train Avg Loss: 1.3960215271938414\n",
      "Validation Loss: 1.3169849855559213\n",
      "Validation IoU: 0.05564781345682834\n",
      "Validation Pixel Acc: 0.7508232094456085\n",
      "\n",
      "\n",
      "Early stop at epoch 5\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2052aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.4566880294254847\n",
      "Test IoU at Test: 0.05575184499509766\n",
      "Test Pixel acc at Test: 0.7289345076758381\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4f946",
   "metadata": {},
   "source": [
    "## Q4.a COSINE ANNEALING LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5df8cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet18(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a76e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1():\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            scheduler.step() # For cosine annealing learning rate\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "        \n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model)\n",
    "            # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6675c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 11.461528778076172\n",
      "Train Avg Loss: 3.8488588503428867\n",
      "Validation Loss: 3.8388543469565257\n",
      "Validation IoU: 0.001378998427807684\n",
      "Validation Pixel Acc: 0.012121172757607507\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 12.173421144485474\n",
      "Train Avg Loss: 3.656428813934326\n",
      "Validation Loss: 3.3680985995701382\n",
      "Validation IoU: 0.0013159682363144568\n",
      "Validation Pixel Acc: 0.015353099945335277\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 11.470860242843628\n",
      "Train Avg Loss: 3.5253778468994867\n",
      "Validation Loss: 3.1234386478151595\n",
      "Validation IoU: 0.0019730341903034026\n",
      "Validation Pixel Acc: 0.016004556817146503\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 12.612285614013672\n",
      "Train Avg Loss: 3.4190412844930376\n",
      "Validation Loss: 2.9157194239752635\n",
      "Validation IoU: 0.011553145074473066\n",
      "Validation Pixel Acc: 0.15404490479227406\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 12.382896423339844\n",
      "Train Avg Loss: 3.3230171169553486\n",
      "Validation Loss: 2.7621196508407593\n",
      "Validation IoU: 0.014005449897335326\n",
      "Validation Pixel Acc: 0.18317801695175834\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 12.109076976776123\n",
      "Train Avg Loss: 3.2364191725140525\n",
      "Validation Loss: 2.616534113883972\n",
      "Validation IoU: 0.021660344687381834\n",
      "Validation Pixel Acc: 0.3089602278550929\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 12.867526769638062\n",
      "Train Avg Loss: 3.1432406196788865\n",
      "Validation Loss: 2.4789529698235646\n",
      "Validation IoU: 0.03335842202771885\n",
      "Validation Pixel Acc: 0.4808578446724671\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 11.170097351074219\n",
      "Train Avg Loss: 3.0601480347769603\n",
      "Validation Loss: 2.333182556288583\n",
      "Validation IoU: 0.03362058710826323\n",
      "Validation Pixel Acc: 0.49045244667342386\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 11.099986791610718\n",
      "Train Avg Loss: 2.9747512094558233\n",
      "Validation Loss: 2.1780143124716624\n",
      "Validation IoU: 0.03363192640669153\n",
      "Validation Pixel Acc: 0.48937522065187683\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 11.781771659851074\n",
      "Train Avg Loss: 2.8978014145578657\n",
      "Validation Loss: 2.08143641267504\n",
      "Validation IoU: 0.0349942329281465\n",
      "Validation Pixel Acc: 0.4939152575790361\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 11.872900485992432\n",
      "Train Avg Loss: 2.8197668117362182\n",
      "Validation Loss: 1.9972645470074244\n",
      "Validation IoU: 0.03851760076595572\n",
      "Validation Pixel Acc: 0.5148975605867349\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 13.211910963058472\n",
      "Train Avg Loss: 2.755346607594263\n",
      "Validation Loss: 1.8828100732394628\n",
      "Validation IoU: 0.04728680234535609\n",
      "Validation Pixel Acc: 0.6079812275077441\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 11.197937965393066\n",
      "Train Avg Loss: 2.686793341086461\n",
      "Validation Loss: 1.8119210600852966\n",
      "Validation IoU: 0.049746578130567445\n",
      "Validation Pixel Acc: 0.6362861833488976\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 11.792654752731323\n",
      "Train Avg Loss: 2.616462862005039\n",
      "Validation Loss: 1.6947115659713745\n",
      "Validation IoU: 0.0494438049721669\n",
      "Validation Pixel Acc: 0.6837370669528973\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 11.009417295455933\n",
      "Train Avg Loss: 2.5493592812901453\n",
      "Validation Loss: 1.6202810151236398\n",
      "Validation IoU: 0.05475835518490391\n",
      "Validation Pixel Acc: 0.6935279245626822\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 11.385447263717651\n",
      "Train Avg Loss: 2.48628210489239\n",
      "Validation Loss: 1.5553791693278722\n",
      "Validation IoU: 0.058722498369653105\n",
      "Validation Pixel Acc: 0.7387532314823251\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 12.476640939712524\n",
      "Train Avg Loss: 2.426388284739326\n",
      "Validation Loss: 1.5127739310264587\n",
      "Validation IoU: 0.05510943237049354\n",
      "Validation Pixel Acc: 0.7501516447817967\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 10.623444557189941\n",
      "Train Avg Loss: 2.3696311601097624\n",
      "Validation Loss: 1.5481592927660262\n",
      "Validation IoU: 0.05971666763036689\n",
      "Validation Pixel Acc: 0.7043499204229683\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 11.500739812850952\n",
      "Train Avg Loss: 2.316574619004601\n",
      "Validation Loss: 1.4293653922421592\n",
      "Validation IoU: 0.05942512594856821\n",
      "Validation Pixel Acc: 0.7541247131525601\n",
      "\n",
      "\n",
      "Finish epoch 19, time elapsed 12.900692224502563\n",
      "Train Avg Loss: 2.267192001215049\n",
      "Validation Loss: 1.4170362608773368\n",
      "Validation IoU: 0.05788734028828988\n",
      "Validation Pixel Acc: 0.7512358996332908\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df41db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.4947880506515503\n",
      "Test IoU at Test: 0.05722389361071704\n",
      "Test Pixel acc at Test: 0.7301294087668548\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e511b76",
   "metadata": {},
   "source": [
    "## Q4.b Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f97876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet18(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61c44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 11.864545345306396\n",
      "Train Avg Loss: 2.752462693623134\n",
      "Validation Loss: 2.881646156311035\n",
      "Validation IoU: 0.0024142864631805333\n",
      "Validation Pixel Acc: 0.0053823932614340386\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 18.102809190750122\n",
      "Train Avg Loss: 2.6775998898914883\n",
      "Validation Loss: 2.5792002848216464\n",
      "Validation IoU: 0.003260135881676691\n",
      "Validation Pixel Acc: 0.020447400151466833\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 29.49026584625244\n",
      "Train Avg Loss: 2.600809403828212\n",
      "Validation Loss: 2.345307230949402\n",
      "Validation IoU: 0.013602761802062931\n",
      "Validation Pixel Acc: 0.15890381927045374\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 20.798587322235107\n",
      "Train Avg Loss: 2.529697443757738\n",
      "Validation Loss: 2.822207655225481\n",
      "Validation IoU: 0.018248389034375367\n",
      "Validation Pixel Acc: 0.1889300554903881\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 14.17847466468811\n",
      "Train Avg Loss: 2.464876183441707\n",
      "Validation Loss: 2.2129252552986145\n",
      "Validation IoU: 0.03271257134568092\n",
      "Validation Pixel Acc: 0.40523533946223583\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 14.397056579589844\n",
      "Train Avg Loss: 2.4122009234769\n",
      "Validation Loss: 1.9846503649439131\n",
      "Validation IoU: 0.04412892252202226\n",
      "Validation Pixel Acc: 0.5813760740763939\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 64.39665961265564\n",
      "Train Avg Loss: 2.3570370686297513\n",
      "Validation Loss: 2.013756905283247\n",
      "Validation IoU: 0.04572586760780047\n",
      "Validation Pixel Acc: 0.56676427546465\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 11.50545048713684\n",
      "Train Avg Loss: 2.310087644628116\n",
      "Validation Loss: 1.8552650128092085\n",
      "Validation IoU: 0.05092818251735387\n",
      "Validation Pixel Acc: 0.6615553430496083\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 11.495622158050537\n",
      "Train Avg Loss: 2.261594388220045\n",
      "Validation Loss: 1.9655136636325292\n",
      "Validation IoU: 0.049099588853320705\n",
      "Validation Pixel Acc: 0.5756952847405704\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 11.985372066497803\n",
      "Train Avg Loss: 2.217840394803456\n",
      "Validation Loss: 1.6901296292032515\n",
      "Validation IoU: 0.054571153730979885\n",
      "Validation Pixel Acc: 0.7348285997574253\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 12.213780879974365\n",
      "Train Avg Loss: 2.181383289300002\n",
      "Validation Loss: 1.6607334869248527\n",
      "Validation IoU: 0.05689678010002487\n",
      "Validation Pixel Acc: 0.7307468069538083\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 12.074979305267334\n",
      "Train Avg Loss: 2.139494692995435\n",
      "Validation Loss: 1.6846260513578142\n",
      "Validation IoU: 0.05785388006045641\n",
      "Validation Pixel Acc: 0.7034816019041544\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 11.801522970199585\n",
      "Train Avg Loss: 2.0998516587110667\n",
      "Validation Loss: 1.7013324328831263\n",
      "Validation IoU: 0.05379102402219104\n",
      "Validation Pixel Acc: 0.6933798564766308\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 11.416609287261963\n",
      "Train Avg Loss: 2.0610806723030244\n",
      "Validation Loss: 1.5481330156326294\n",
      "Validation IoU: 0.06125796042159133\n",
      "Validation Pixel Acc: 0.735487210020727\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 11.18451976776123\n",
      "Train Avg Loss: 2.025234379654839\n",
      "Validation Loss: 1.4497935346194677\n",
      "Validation IoU: 0.06266855849526495\n",
      "Validation Pixel Acc: 0.7469495589809584\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 11.108712196350098\n",
      "Train Avg Loss: 1.9891501303230013\n",
      "Validation Loss: 1.4838360122271947\n",
      "Validation IoU: 0.06290734244012196\n",
      "Validation Pixel Acc: 0.7320223527469024\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 11.29227590560913\n",
      "Train Avg Loss: 1.958282326449867\n",
      "Validation Loss: 1.4468743630817957\n",
      "Validation IoU: 0.055482083186831496\n",
      "Validation Pixel Acc: 0.732308541790042\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 10.820692777633667\n",
      "Train Avg Loss: 1.932119692601855\n",
      "Validation Loss: 1.4636351295879908\n",
      "Validation IoU: 0.060856567212578316\n",
      "Validation Pixel Acc: 0.7086897335664177\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 10.802333116531372\n",
      "Train Avg Loss: 1.9030775158925164\n",
      "Validation Loss: 1.3898052956376756\n",
      "Validation IoU: 0.06261948287619262\n",
      "Validation Pixel Acc: 0.7388089104922103\n",
      "\n",
      "\n",
      "Early stop at epoch 18\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0f9f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.3352243900299072\n",
      "Test IoU at Test: 0.062609251938479\n",
      "Test Pixel acc at Test: 0.727287003319743\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673b97d",
   "metadata": {},
   "source": [
    "## Q4.c Weight Imbalance + (Image Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a945981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights():\n",
    "    ans = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # Iterate through the training set\n",
    "    for iter, (inputs, labels) in enumerate(train_loader):  \n",
    "        unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "        # Count number of each class\n",
    "        for i in range(len(unique_elements)):\n",
    "            ans[unique_elements[i]] += counts[i]\n",
    "\n",
    "    normalized = [tensor.tolist() for tensor in ans]\n",
    "    #normalized = [num/sum(normalized) for num in normalized]\n",
    "    normalized = [1/(1-pow(0.1,num/50000)) for num in normalized]\n",
    "    return torch.tensor(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70afee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.1215, 1.1570, 1.0170, 1.1304, 1.0395, 1.0001, 1.0334, 1.0002,\n",
      "        1.0061, 1.0280, 1.0023, 1.0014, 1.0195, 1.0275, 1.0000, 1.3059, 1.5267,\n",
      "        1.0004, 1.0040, 1.0025])\n"
     ]
    }
   ],
   "source": [
    "class_weights = getClassWeights()\n",
    "print(class_weights)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet18(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86fdada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 12.792518854141235\n",
      "Train Avg Loss: 2.9731689180646623\n",
      "Validation Loss: 3.3386610405785695\n",
      "Validation IoU: 0.003711040629156048\n",
      "Validation Pixel Acc: 0.013152827048788266\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 13.60629391670227\n",
      "Train Avg Loss: 2.8419202055249895\n",
      "Validation Loss: 2.523624760763986\n",
      "Validation IoU: 0.0008459458696763309\n",
      "Validation Pixel Acc: 0.009729537741435859\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 11.590258121490479\n",
      "Train Avg Loss: 2.664101407641456\n",
      "Validation Loss: 2.1430900607790266\n",
      "Validation IoU: 0.04553097016372226\n",
      "Validation Pixel Acc: 0.6137401881092839\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 13.19899845123291\n",
      "Train Avg Loss: 2.502972113234656\n",
      "Validation Loss: 1.7477883441107613\n",
      "Validation IoU: 0.049110519663740394\n",
      "Validation Pixel Acc: 0.6178634954958546\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 15.893030405044556\n",
      "Train Avg Loss: 2.337155340399061\n",
      "Validation Loss: 1.6107122216905867\n",
      "Validation IoU: 0.05071620236024461\n",
      "Validation Pixel Acc: 0.6155104211746083\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 11.309734582901001\n",
      "Train Avg Loss: 2.195344489245188\n",
      "Validation Loss: 1.4554550009114402\n",
      "Validation IoU: 0.0578515165143526\n",
      "Validation Pixel Acc: 0.7024724042797923\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 13.374291896820068\n",
      "Train Avg Loss: 2.074860487665449\n",
      "Validation Loss: 1.444664444242205\n",
      "Validation IoU: 0.06060844082436938\n",
      "Validation Pixel Acc: 0.7004027786477315\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 11.90501618385315\n",
      "Train Avg Loss: 1.976784079202584\n",
      "Validation Loss: 1.3469045162200928\n",
      "Validation IoU: 0.0560234179674688\n",
      "Validation Pixel Acc: 0.7515503641467748\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 11.189733505249023\n",
      "Train Avg Loss: 1.8926544492206876\n",
      "Validation Loss: 1.341430902481079\n",
      "Validation IoU: 0.057018230039212976\n",
      "Validation Pixel Acc: 0.748737301840379\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 14.178627252578735\n",
      "Train Avg Loss: 1.8246448184762682\n",
      "Validation Loss: 1.303975760936737\n",
      "Validation IoU: 0.05832961792543567\n",
      "Validation Pixel Acc: 0.7508664145066508\n",
      "\n",
      "\n",
      "Early stop at epoch 9\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14daff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.3887752549988883\n",
      "Test IoU at Test: 0.057640198672544454\n",
      "Test Pixel acc at Test: 0.7280713851528334\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
