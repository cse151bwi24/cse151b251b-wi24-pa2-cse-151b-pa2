{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet_18_fcn import *\n",
    "from resnet_34_fcn import *\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "# Initialize Weights with Xavier Weight Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "#         if m.bias is not None:  # Check if the bias exists\n",
    "        torch.nn.init.normal_(m.bias.data)  # Xavier not applicable for biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750ceef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCN_ResNet34(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset =voc.VOC('train', transform=input_transform, target_transform=target_transform)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 16, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "n_class = 21\n",
    "\n",
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad2ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-4)\n",
    "\n",
    "# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fcn_model = fcn_model.to(device)\n",
    "max_model = fcn_model\n",
    "\n",
    "earlystop = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5198b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            #if iter % 10 == 0:\n",
    "            #    print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "\n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        # Save current IoU if better than stored best\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model) # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e42b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode. DONE\n",
    "    - Disable gradient calculations. DONE\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Validation Set\n",
    "        for iter, (input, label) in enumerate(val_loader):\n",
    "            # label = (16, 224, 224) / batch size 16 of 244*244 masks\n",
    "            # output = (16, 21, 224, 224) / batch size 16 of 21 possible classes of 244*244 masks\n",
    "            \n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "            \n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    print(f\"Validation Loss: {np.mean(losses)}\")\n",
    "    print(f\"Validation IoU: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Validation Pixel Acc: {np.mean(accuracy)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "def modelTest():\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model = copy.deepcopy(max_model) # Asssume model loaded with the best weights.\n",
    "    \n",
    "    fcn_model.eval()  # Put in eval mode (disables batchnorm/dropout) !\n",
    "\n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad():  # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Test Set\n",
    "        for iter, (input, label) in enumerate(test_loader):\n",
    "\n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    print(f\"Test Loss at Test: {np.mean(losses)}\")\n",
    "    print(f\"Test IoU at Test: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Test Pixel acc at Test: {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = fcn_model(inputs)\n",
    "    \n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     val(0)  # show the accuracy before training\n",
    "#     train()\n",
    "#     modelTest()\n",
    "\n",
    "#     # housekeeping\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05d0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.3556559085845947\n",
      "Train Avg Loss: 0.9802679802690234\n",
      "Validation Loss: 1.073997552905764\n",
      "Validation IoU: 0.07851260735273782\n",
      "Validation Pixel Acc: 0.7618555363691234\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.2676329612731934\n",
      "Train Avg Loss: 0.9238160508019584\n",
      "Validation Loss: 1.0749568087714059\n",
      "Validation IoU: 0.08399816998726871\n",
      "Validation Pixel Acc: 0.7718467067351493\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.333735942840576\n",
      "Train Avg Loss: 0.9066412207626161\n",
      "Validation Loss: 1.0440470959459032\n",
      "Validation IoU: 0.0840849129705137\n",
      "Validation Pixel Acc: 0.7710566484545829\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 3.0020248889923096\n",
      "Train Avg Loss: 0.8845059382064002\n",
      "Validation Loss: 1.060536001409803\n",
      "Validation IoU: 0.086545168833566\n",
      "Validation Pixel Acc: 0.7715032905600856\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.184597969055176\n",
      "Train Avg Loss: 0.8872504958084652\n",
      "Validation Loss: 1.010516575404576\n",
      "Validation IoU: 0.08735910334565357\n",
      "Validation Pixel Acc: 0.7756700521307854\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 3.5469515323638916\n",
      "Train Avg Loss: 0.8763094430878049\n",
      "Validation Loss: 1.0403710220541273\n",
      "Validation IoU: 0.09447257843729795\n",
      "Validation Pixel Acc: 0.7772829817613429\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.3011279106140137\n",
      "Train Avg Loss: 0.8653354821156483\n",
      "Validation Loss: 1.0632247754505701\n",
      "Validation IoU: 0.08649870379972917\n",
      "Validation Pixel Acc: 0.7700246916567967\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.30024790763855\n",
      "Train Avg Loss: 0.851652263530663\n",
      "Validation Loss: 1.0441109793526786\n",
      "Validation IoU: 0.08995106549713132\n",
      "Validation Pixel Acc: 0.775862054852633\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.2306630611419678\n",
      "Train Avg Loss: 0.8816727584316617\n",
      "Validation Loss: 1.0490227554525648\n",
      "Validation IoU: 0.10126700933503201\n",
      "Validation Pixel Acc: 0.7766782354682943\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.118187427520752\n",
      "Train Avg Loss: 0.8714552926165717\n",
      "Validation Loss: 1.0261807228837694\n",
      "Validation IoU: 0.09546778656171277\n",
      "Validation Pixel Acc: 0.7793633374806397\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.216966152191162\n",
      "Train Avg Loss: 0.8607049139289112\n",
      "Validation Loss: 1.034912931067603\n",
      "Validation IoU: 0.09622484339251257\n",
      "Validation Pixel Acc: 0.7781038957156524\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 3.358010768890381\n",
      "Train Avg Loss: 0.8576241852272124\n",
      "Validation Loss: 1.069327290569033\n",
      "Validation IoU: 0.09556877746819084\n",
      "Validation Pixel Acc: 0.7794884150646866\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 3.193361282348633\n",
      "Train Avg Loss: 0.8486748537519476\n",
      "Validation Loss: 1.027504414319992\n",
      "Validation IoU: 0.1047954414899231\n",
      "Validation Pixel Acc: 0.7741860792866254\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 3.339716672897339\n",
      "Train Avg Loss: 0.841804383664715\n",
      "Validation Loss: 1.029675794499261\n",
      "Validation IoU: 0.10627420777606492\n",
      "Validation Pixel Acc: 0.7821878950380375\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 3.2441070079803467\n",
      "Train Avg Loss: 0.8330987419400896\n",
      "Validation Loss: 1.0658133625984192\n",
      "Validation IoU: 0.1065486428020563\n",
      "Validation Pixel Acc: 0.785557978771866\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 3.3236429691314697\n",
      "Train Avg Loss: 0.8238890205643007\n",
      "Validation Loss: 1.01896756035941\n",
      "Validation IoU: 0.10880982984107514\n",
      "Validation Pixel Acc: 0.7838220891034986\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 3.1408560276031494\n",
      "Train Avg Loss: 0.8156242423197803\n",
      "Validation Loss: 1.0115762054920197\n",
      "Validation IoU: 0.1126379227214076\n",
      "Validation Pixel Acc: 0.787720723054847\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 3.245567798614502\n",
      "Train Avg Loss: 0.8115051464428977\n",
      "Validation Loss: 1.0346274375915527\n",
      "Validation IoU: 0.11122102424221701\n",
      "Validation Pixel Acc: 0.7913970858293095\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 3.287322998046875\n",
      "Train Avg Loss: 0.804149476881314\n",
      "Validation Loss: 1.043628718171801\n",
      "Validation IoU: 0.10552704874466004\n",
      "Validation Pixel Acc: 0.7755451169027879\n",
      "\n",
      "\n",
      "Finish epoch 19, time elapsed 3.1041109561920166\n",
      "Train Avg Loss: 0.8031346091202327\n",
      "Validation Loss: 0.9846695831843785\n",
      "Validation IoU: 0.11140592520814543\n",
      "Validation Pixel Acc: 0.7891755662923651\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2052aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.0503004150731223\n",
      "Test IoU at Test: 0.12382800403897062\n",
      "Test Pixel acc at Test: 0.7688624434846484\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4f946",
   "metadata": {},
   "source": [
    "## Q4.a COSINE ANNEALING LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df8cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a76e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1():\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            scheduler.step() # For cosine annealing learning rate\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "        \n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model)\n",
    "            # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6675c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.144139289855957\n",
      "Train Avg Loss: 3.0407685382025584\n",
      "Validation Loss: 2.9449727024350847\n",
      "Validation IoU: 0.03033509839788575\n",
      "Validation Pixel Acc: 0.3362581214126275\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.3123090267181396\n",
      "Train Avg Loss: 2.7771624497004916\n",
      "Validation Loss: 2.9277971982955933\n",
      "Validation IoU: 0.04333676457236222\n",
      "Validation Pixel Acc: 0.6198120295132562\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.1016955375671387\n",
      "Train Avg Loss: 2.5145740679332187\n",
      "Validation Loss: 2.1911818981170654\n",
      "Validation IoU: 0.05286295347671104\n",
      "Validation Pixel Acc: 0.7012355259486608\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 3.246269464492798\n",
      "Train Avg Loss: 2.3795946666172574\n",
      "Validation Loss: 2.1329251868384227\n",
      "Validation IoU: 0.054918439730762526\n",
      "Validation Pixel Acc: 0.7084538140032798\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.081167221069336\n",
      "Train Avg Loss: 2.1382357137543813\n",
      "Validation Loss: 2.013813410486494\n",
      "Validation IoU: 0.057676971377836554\n",
      "Validation Pixel Acc: 0.7169075746230412\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 3.244863748550415\n",
      "Train Avg Loss: 2.0235781414168224\n",
      "Validation Loss: 1.8503010272979736\n",
      "Validation IoU: 0.05878161849407875\n",
      "Validation Pixel Acc: 0.730540088175337\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.0626437664031982\n",
      "Train Avg Loss: 1.9027287704604012\n",
      "Validation Loss: 1.9704755714961462\n",
      "Validation IoU: 0.05949994905301937\n",
      "Validation Pixel Acc: 0.7167967148494443\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.145350217819214\n",
      "Train Avg Loss: 1.7777749470302038\n",
      "Validation Loss: 2.1525056106703624\n",
      "Validation IoU: 0.059871513283330555\n",
      "Validation Pixel Acc: 0.7007260158527696\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.106933116912842\n",
      "Train Avg Loss: 1.6778257744652885\n",
      "Validation Loss: 1.495028555393219\n",
      "Validation IoU: 0.06817707455703363\n",
      "Validation Pixel Acc: 0.7634727544756741\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.3256382942199707\n",
      "Train Avg Loss: 1.6347521458353316\n",
      "Validation Loss: 1.5185975432395935\n",
      "Validation IoU: 0.06715680180255361\n",
      "Validation Pixel Acc: 0.7561640881240889\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.112316131591797\n",
      "Train Avg Loss: 1.6505942855562483\n",
      "Validation Loss: 1.6187511427061898\n",
      "Validation IoU: 0.06776032224203701\n",
      "Validation Pixel Acc: 0.7522786043128189\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 3.3098409175872803\n",
      "Train Avg Loss: 1.4707582337515694\n",
      "Validation Loss: 1.599564450127738\n",
      "Validation IoU: 0.06705600596806145\n",
      "Validation Pixel Acc: 0.7437420814447432\n",
      "\n",
      "\n",
      "Early stop at epoch 11\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df41db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.7479261926242284\n",
      "Test IoU at Test: 0.06461913530705249\n",
      "Test Pixel acc at Test: 0.7132075451553389\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e511b76",
   "metadata": {},
   "source": [
    "## Q4.b Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f97876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.2206363677978516\n",
      "Train Avg Loss: 2.8587160451071605\n",
      "Validation Loss: 2.816209844180516\n",
      "Validation IoU: 0.044183768605920805\n",
      "Validation Pixel Acc: 0.5775929976482781\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.0145652294158936\n",
      "Train Avg Loss: 2.599846839904785\n",
      "Validation Loss: 2.434306468282427\n",
      "Validation IoU: 0.05095173401966833\n",
      "Validation Pixel Acc: 0.6838541903926748\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.1507327556610107\n",
      "Train Avg Loss: 2.2725536482674733\n",
      "Validation Loss: 2.0983338270868575\n",
      "Validation IoU: 0.05592585548426308\n",
      "Validation Pixel Acc: 0.7118182390841382\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 3.2615063190460205\n",
      "Train Avg Loss: 2.1737447551318576\n",
      "Validation Loss: 2.2848498736109053\n",
      "Validation IoU: 0.0520654131949068\n",
      "Validation Pixel Acc: 0.6728932906170281\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.2354679107666016\n",
      "Train Avg Loss: 2.0296574405261447\n",
      "Validation Loss: 1.8286787697247096\n",
      "Validation IoU: 0.059507923008250495\n",
      "Validation Pixel Acc: 0.7275374076109238\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 3.3935670852661133\n",
      "Train Avg Loss: 1.917983421257564\n",
      "Validation Loss: 2.658998829977853\n",
      "Validation IoU: 0.052658921729278343\n",
      "Validation Pixel Acc: 0.6409963357552843\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.4101459980010986\n",
      "Train Avg Loss: 1.8145959547587804\n",
      "Validation Loss: 1.5322200400488717\n",
      "Validation IoU: 0.06790625027104681\n",
      "Validation Pixel Acc: 0.7593322931851312\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.165515661239624\n",
      "Train Avg Loss: 1.7443014468465532\n",
      "Validation Loss: 1.593745265688215\n",
      "Validation IoU: 0.06724606202552551\n",
      "Validation Pixel Acc: 0.747114674203945\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.08748197555542\n",
      "Train Avg Loss: 1.6422120928764343\n",
      "Validation Loss: 1.561829379626683\n",
      "Validation IoU: 0.06983778736262032\n",
      "Validation Pixel Acc: 0.7516273965640945\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.4285638332366943\n",
      "Train Avg Loss: 1.4588136502674647\n",
      "Validation Loss: 1.6174129758562361\n",
      "Validation IoU: 0.07750194436070233\n",
      "Validation Pixel Acc: 0.7447965127038538\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.17409610748291\n",
      "Train Avg Loss: 1.3689472419875008\n",
      "Validation Loss: 1.8571535348892212\n",
      "Validation IoU: 0.06335603572298516\n",
      "Validation Pixel Acc: 0.7140784972610695\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 3.267578601837158\n",
      "Train Avg Loss: 1.432490689413888\n",
      "Validation Loss: 1.3268678784370422\n",
      "Validation IoU: 0.07958126201982829\n",
      "Validation Pixel Acc: 0.7672201885078808\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 3.1500000953674316\n",
      "Train Avg Loss: 1.3840721079281397\n",
      "Validation Loss: 1.4001175931521825\n",
      "Validation IoU: 0.06976930002359821\n",
      "Validation Pixel Acc: 0.7531941850400875\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 3.054236888885498\n",
      "Train Avg Loss: 1.36696834223611\n",
      "Validation Loss: 1.39929176228387\n",
      "Validation IoU: 0.07833753230567102\n",
      "Validation Pixel Acc: 0.7576009055268315\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 2.952641010284424\n",
      "Train Avg Loss: 1.2658660582133703\n",
      "Validation Loss: 1.7040933881487166\n",
      "Validation IoU: 0.07840922676018579\n",
      "Validation Pixel Acc: 0.7327917871947885\n",
      "\n",
      "\n",
      "Early stop at epoch 14\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0f9f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.8853135449545724\n",
      "Test IoU at Test: 0.07405152428253936\n",
      "Test Pixel acc at Test: 0.7016228767595208\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673b97d",
   "metadata": {},
   "source": [
    "## Q4.c Weight Imbalance + (Image Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a945981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights():\n",
    "    ans = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # Iterate through the training set\n",
    "    for iter, (inputs, labels) in enumerate(train_loader):  \n",
    "        unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "        # Count number of each class\n",
    "        for i in range(len(unique_elements)):\n",
    "            ans[unique_elements[i]] += counts[i]\n",
    "\n",
    "    normalized = [tensor.tolist() for tensor in ans]\n",
    "    #normalized = [num/sum(normalized) for num in normalized]\n",
    "    normalized = [1/(1-pow(0.1,num/50000)) for num in normalized]\n",
    "    return torch.tensor(normalized)\n",
    "#     class_counts = [0] * 21  # Assuming 21 classes\n",
    "    \n",
    "#     # Iterate through the training set\n",
    "#     for _, labels in train_loader:\n",
    "#         labels = labels.view(-1)  # Flatten labels tensor to 1D, if necessary\n",
    "#         unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "#         # Ensure unique_elements is a tensor of integers for indexing\n",
    "#         unique_elements = unique_elements.to(torch.int64)\n",
    "        \n",
    "#         # Update counts for each class\n",
    "#         for i in range(len(unique_elements)):\n",
    "#             element = unique_elements[i].item()  # Convert to Python int\n",
    "#             count = counts[i].item()\n",
    "#             if element < len(class_counts):  # Check is now valid\n",
    "#                 class_counts[element] += count\n",
    "    \n",
    "#     # Avoid division by zero for classes not present in the dataset\n",
    "#     class_counts = [max(count, 1) for count in class_counts]\n",
    "\n",
    "#     # Calculate weights inversely proportional to class frequencies\n",
    "#     total_count = sum(class_counts)\n",
    "#     weights = [total_count / count for count in class_counts]\n",
    "    \n",
    "#     # Normalize weights (optional)\n",
    "#     min_weight = min(weights)\n",
    "#     normalized_weights = [weight / min_weight for weight in weights]\n",
    "\n",
    "#     return torch.tensor(normalized_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70afee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.1215, 1.1613, 1.0169, 1.1303, 1.0395, 1.0001, 1.0340, 1.0002,\n",
      "        1.0060, 1.0280, 1.0025, 1.0013, 1.0195, 1.0268, 1.0000, 1.3122, 1.5279,\n",
      "        1.0004, 1.0041, 1.0025])\n"
     ]
    }
   ],
   "source": [
    "class_weights = getClassWeights()\n",
    "print(class_weights)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 5\n",
    "max_model = fcn_model\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-2)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "# T_max = 10\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=T_max, T_mult=1, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86fdada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 3.1398379802703857\n",
      "Train Avg Loss: 2.7007069247109547\n",
      "Validation Loss: 5.171793631144932\n",
      "Validation IoU: 0.03258818984972652\n",
      "Validation Pixel Acc: 0.4684217625387208\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 3.0589396953582764\n",
      "Train Avg Loss: 2.0742288572447642\n",
      "Validation Loss: 1.9567525471959795\n",
      "Validation IoU: 0.06467935824710723\n",
      "Validation Pixel Acc: 0.7250223676942875\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 3.155501365661621\n",
      "Train Avg Loss: 1.466308321271624\n",
      "Validation Loss: 1.2651709020137787\n",
      "Validation IoU: 0.06775255963608295\n",
      "Validation Pixel Acc: 0.7602605080117985\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 3.1819887161254883\n",
      "Train Avg Loss: 1.300225555896759\n",
      "Validation Loss: 1.1814778915473394\n",
      "Validation IoU: 0.06587561035504445\n",
      "Validation Pixel Acc: 0.7602094377790178\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 3.2037124633789062\n",
      "Train Avg Loss: 1.123200339930398\n",
      "Validation Loss: 1.1234589091369085\n",
      "Validation IoU: 0.07173672327246364\n",
      "Validation Pixel Acc: 0.7627502975241437\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 3.229526996612549\n",
      "Train Avg Loss: 1.0903197526931763\n",
      "Validation Loss: 1.1925476150853294\n",
      "Validation IoU: 0.057364916625836315\n",
      "Validation Pixel Acc: 0.7562908028027058\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 3.5019466876983643\n",
      "Train Avg Loss: 1.0578763442380088\n",
      "Validation Loss: 1.120881267956325\n",
      "Validation IoU: 0.06838482836465894\n",
      "Validation Pixel Acc: 0.7616334431372996\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 3.2745718955993652\n",
      "Train Avg Loss: 1.0562426447868347\n",
      "Validation Loss: 1.1266426614352636\n",
      "Validation IoU: 0.06922344620246458\n",
      "Validation Pixel Acc: 0.7610699445096119\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 3.4594085216522217\n",
      "Train Avg Loss: 1.116725959948131\n",
      "Validation Loss: 1.1084667955126082\n",
      "Validation IoU: 0.0711362284737456\n",
      "Validation Pixel Acc: 0.7648561527708182\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 3.2407641410827637\n",
      "Train Avg Loss: 1.006367266178131\n",
      "Validation Loss: 1.1426218450069427\n",
      "Validation IoU: 0.07357930059039566\n",
      "Validation Pixel Acc: 0.7605368033094936\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 3.336884021759033\n",
      "Train Avg Loss: 1.0258856160300118\n",
      "Validation Loss: 1.11661839059421\n",
      "Validation IoU: 0.0769549829525816\n",
      "Validation Pixel Acc: 0.7649571543879828\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 3.368557929992676\n",
      "Train Avg Loss: 1.017707769359861\n",
      "Validation Loss: 1.1024587196963174\n",
      "Validation IoU: 0.07523503680118503\n",
      "Validation Pixel Acc: 0.7679483397013939\n",
      "\n",
      "\n",
      "Finish epoch 12, time elapsed 3.2528419494628906\n",
      "Train Avg Loss: 0.960938389812197\n",
      "Validation Loss: 1.1099257596901484\n",
      "Validation IoU: 0.07730636281976473\n",
      "Validation Pixel Acc: 0.7608958786500091\n",
      "\n",
      "\n",
      "Finish epoch 13, time elapsed 3.046724796295166\n",
      "Train Avg Loss: 0.9816347403185708\n",
      "Validation Loss: 1.1050672914300645\n",
      "Validation IoU: 0.07848655596593841\n",
      "Validation Pixel Acc: 0.7692865755398142\n",
      "\n",
      "\n",
      "Finish epoch 14, time elapsed 3.2231521606445312\n",
      "Train Avg Loss: 0.9359165685517448\n",
      "Validation Loss: 1.126435820545469\n",
      "Validation IoU: 0.07935552918276825\n",
      "Validation Pixel Acc: 0.7627957446929664\n",
      "\n",
      "\n",
      "Finish epoch 15, time elapsed 3.458696126937866\n",
      "Train Avg Loss: 1.0053117275238037\n",
      "Validation Loss: 1.0763478832585471\n",
      "Validation IoU: 0.0810594796206848\n",
      "Validation Pixel Acc: 0.7712792221380739\n",
      "\n",
      "\n",
      "Finish epoch 16, time elapsed 3.4283807277679443\n",
      "Train Avg Loss: 0.9282296214784894\n",
      "Validation Loss: 1.067480913230351\n",
      "Validation IoU: 0.0691466739070445\n",
      "Validation Pixel Acc: 0.7691890794403698\n",
      "\n",
      "\n",
      "Finish epoch 17, time elapsed 3.2273871898651123\n",
      "Train Avg Loss: 0.9175979367324284\n",
      "Validation Loss: 1.0333767235279083\n",
      "Validation IoU: 0.07052704306858835\n",
      "Validation Pixel Acc: 0.7707497821952443\n",
      "\n",
      "\n",
      "Finish epoch 18, time elapsed 3.0511064529418945\n",
      "Train Avg Loss: 0.9144921473094395\n",
      "Validation Loss: 1.0322574760232652\n",
      "Validation IoU: 0.07088848239052585\n",
      "Validation Pixel Acc: 0.768744359141536\n",
      "\n",
      "\n",
      "Finish epoch 19, time elapsed 3.0859458446502686\n",
      "Train Avg Loss: 0.887499430349895\n",
      "Validation Loss: 1.019382051059178\n",
      "Validation IoU: 0.07404007884077088\n",
      "Validation Pixel Acc: 0.7708489331837647\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14daff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.1259074466569083\n",
      "Test IoU at Test: 0.07159268437145956\n",
      "Test Pixel acc at Test: 0.7408034433081269\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79be37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
