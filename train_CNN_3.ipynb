{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from resnet_18_fcn import *\n",
    "from resnet_34_fcn import *\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "# Initialize Weights with Xavier Weight Initialization\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        if m.bias is not None:  # Check if the bias exists\n",
    "            torch.nn.init.normal_(m.bias.data)  # Xavier not applicable for biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750ceef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FCN_ResNet34(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (deconv1): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv2): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv4): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv5): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Conv2d(32, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset =voc.VOC('train', transform=input_transform, target_transform=target_transform)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 16, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 16, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "n_class = 21\n",
    "\n",
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ad2ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-4)\n",
    "\n",
    "# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fcn_model = fcn_model.to(device)\n",
    "max_model = fcn_model\n",
    "\n",
    "earlystop = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5198b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "\n",
    "            #if iter % 10 == 0:\n",
    "            #    print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "\n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        # Save current IoU if better than stored best\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model) # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e42b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode. DONE\n",
    "    - Disable gradient calculations. DONE\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "    \n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Validation Set\n",
    "        for iter, (input, label) in enumerate(val_loader):\n",
    "            # label = (16, 224, 224) / batch size 16 of 244*244 masks\n",
    "            # output = (16, 21, 224, 224) / batch size 16 of 21 possible classes of 244*244 masks\n",
    "            \n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "            \n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "    \n",
    "    print(f\"Validation Loss: {np.mean(losses)}\")\n",
    "    print(f\"Validation IoU: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Validation Pixel Acc: {np.mean(accuracy)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    fcn_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "def modelTest():\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model = copy.deepcopy(max_model) # Asssume model loaded with the best weights.\n",
    "    \n",
    "    fcn_model.eval()  # Put in eval mode (disables batchnorm/dropout) !\n",
    "\n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad():  # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Test Set\n",
    "        for iter, (input, label) in enumerate(test_loader):\n",
    "\n",
    "            input, label = input.to(device), label.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            output = fcn_model.forward(input) # Perform forward pass to get outputs.\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            prediction = output.view(N, n_class, -1).argmax(dim=1).view(N, H, W) # Find the prediction for each pixel\n",
    "            \n",
    "            loss = criterion(output, label) # Compute loss and accumulate it.\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            meanIOU = util.iou(prediction, label, n_class) # Calculate Intersection over Union (IoU) scores\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label) # Calculate pixel accuracy\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    print(f\"Test Loss at Test: {np.mean(losses)}\")\n",
    "    print(f\"Test IoU at Test: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Test Pixel acc at Test: {np.mean(accuracy)}\")\n",
    "\n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    fcn_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = fcn_model(inputs)\n",
    "    \n",
    "    fcn_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     val(0)  # show the accuracy before training\n",
    "#     train()\n",
    "#     modelTest()\n",
    "\n",
    "#     # housekeeping\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05d0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 28.398324251174927\n",
      "Train Avg Loss: 3.3141595806394304\n",
      "Validation Loss: 3.03933915070125\n",
      "Validation IoU: 0.0006986148281381277\n",
      "Validation Pixel Acc: 0.004875943820608601\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 28.197465181350708\n",
      "Train Avg Loss: 3.2375641890934537\n",
      "Validation Loss: 2.990268247468131\n",
      "Validation IoU: 0.00038378205046383373\n",
      "Validation Pixel Acc: 0.0047214519178207\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 32.72592353820801\n",
      "Train Avg Loss: 3.1865850119363692\n",
      "Validation Loss: 2.892855797495161\n",
      "Validation IoU: 0.00038159010547670426\n",
      "Validation Pixel Acc: 0.004688265163766399\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 27.961517095565796\n",
      "Train Avg Loss: 3.143535396882466\n",
      "Validation Loss: 2.7838507890701294\n",
      "Validation IoU: 0.0005183367858050099\n",
      "Validation Pixel Acc: 0.004759265243485787\n",
      "\n",
      "\n",
      "Early stop at epoch 3\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2052aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 2.8496783460889543\n",
      "Test IoU at Test: 0.0004603377634726568\n",
      "Test Pixel acc at Test: 0.006223895459411442\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e4f946",
   "metadata": {},
   "source": [
    "## Q4.a COSINE ANNEALING LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5df8cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a76e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train1():\n",
    "    patience = 0\n",
    "    best_iou_score = 0.0\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            \n",
    "            optimizer.zero_grad() # reset optimizer gradients\n",
    "\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # both inputs and labels in device as model\n",
    "\n",
    "            outputs = fcn_model(inputs) #  Compute outputs. Automatically in the same device as the model's\n",
    "\n",
    "            loss = criterion(outputs, labels) #Calculate loss\n",
    "\n",
    "            loss.backward() # Bckpropagate model\n",
    "\n",
    "            optimizer.step() # Update the weights\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            scheduler.step() # For cosine annealing learning rate\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "        print(\"Train Avg Loss: {}\".format(np.mean(losses)))\n",
    "        \n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            patience = 0\n",
    "            max_model = copy.deepcopy(fcn_model)\n",
    "            # save the best model\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stop if patience level is met\n",
    "        if patience >= earlystop:\n",
    "            print(\"Early stop at epoch \" + str(epoch))\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6675c534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 27.06205725669861\n",
      "Train Avg Loss: 3.0580615997314453\n",
      "Validation Loss: 2.985409906932286\n",
      "Validation IoU: 0.0009069333400389655\n",
      "Validation Pixel Acc: 0.00509323253575984\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 27.714810371398926\n",
      "Train Avg Loss: 3.0240070138658797\n",
      "Validation Loss: 2.7795808826174055\n",
      "Validation IoU: 0.001623848682575847\n",
      "Validation Pixel Acc: 0.021768339729865162\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 28.089276790618896\n",
      "Train Avg Loss: 2.9676462695712136\n",
      "Validation Loss: 2.654994079044887\n",
      "Validation IoU: 0.0016034590855567704\n",
      "Validation Pixel Acc: 0.0218048184675656\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 28.080803871154785\n",
      "Train Avg Loss: 2.935958364180156\n",
      "Validation Loss: 2.6019285917282104\n",
      "Validation IoU: 0.0022127949318165\n",
      "Validation Pixel Acc: 0.02381728814572704\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 35.73695111274719\n",
      "Train Avg Loss: 2.8975371973855153\n",
      "Validation Loss: 2.727135385785784\n",
      "Validation IoU: 0.0028959634781005883\n",
      "Validation Pixel Acc: 0.03292109987131014\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 29.107130527496338\n",
      "Train Avg Loss: 2.8652232062248957\n",
      "Validation Loss: 2.5770233869552612\n",
      "Validation IoU: 0.014873167713534448\n",
      "Validation Pixel Acc: 0.19186764375113885\n",
      "\n",
      "\n",
      "Finish epoch 6, time elapsed 28.402317762374878\n",
      "Train Avg Loss: 2.8314559848941103\n",
      "Validation Loss: 2.4798162153788974\n",
      "Validation IoU: 0.015561409392551127\n",
      "Validation Pixel Acc: 0.22637079978475763\n",
      "\n",
      "\n",
      "Finish epoch 7, time elapsed 30.07237482070923\n",
      "Train Avg Loss: 2.8020736319678172\n",
      "Validation Loss: 3.1083754982267107\n",
      "Validation IoU: 0.03552511527434592\n",
      "Validation Pixel Acc: 0.5252269155430029\n",
      "\n",
      "\n",
      "Finish epoch 8, time elapsed 34.52052593231201\n",
      "Train Avg Loss: 2.766802990247333\n",
      "Validation Loss: 2.390275137765067\n",
      "Validation IoU: 0.03978232546145651\n",
      "Validation Pixel Acc: 0.5982613521831723\n",
      "\n",
      "\n",
      "Finish epoch 9, time elapsed 35.66518592834473\n",
      "Train Avg Loss: 2.732897562640054\n",
      "Validation Loss: 2.437642071928297\n",
      "Validation IoU: 0.03643960408335402\n",
      "Validation Pixel Acc: 0.6493860895362609\n",
      "\n",
      "\n",
      "Finish epoch 10, time elapsed 28.554747819900513\n",
      "Train Avg Loss: 2.7093933449163066\n",
      "Validation Loss: 2.1128485883985246\n",
      "Validation IoU: 0.03798310428844393\n",
      "Validation Pixel Acc: 0.667162356362746\n",
      "\n",
      "\n",
      "Finish epoch 11, time elapsed 29.345492124557495\n",
      "Train Avg Loss: 2.6697221057755605\n",
      "Validation Loss: 2.4290812270981923\n",
      "Validation IoU: 0.03692402996895687\n",
      "Validation Pixel Acc: 0.6607469030441419\n",
      "\n",
      "\n",
      "Early stop at epoch 11\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df41db87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 2.6762146098273143\n",
      "Test IoU at Test: 0.039501374514320335\n",
      "Test Pixel acc at Test: 0.6206669487689048\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e511b76",
   "metadata": {},
   "source": [
    "## Q4.b Image Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f97876fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61c44a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 32.79289436340332\n",
      "Train Avg Loss: 3.67662969657353\n",
      "Validation Loss: 3.7527910130364552\n",
      "Validation IoU: 0.005163105983755885\n",
      "Validation Pixel Acc: 0.047436470053981404\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 31.284151077270508\n",
      "Train Avg Loss: 3.601178765296936\n",
      "Validation Loss: 3.3133995703288486\n",
      "Validation IoU: 0.0037010700310232724\n",
      "Validation Pixel Acc: 0.053846585020727034\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 28.172730207443237\n",
      "Train Avg Loss: 3.5426324038278487\n",
      "Validation Loss: 3.2292477743966237\n",
      "Validation IoU: 0.0036933035855174446\n",
      "Validation Pixel Acc: 0.054086365991709184\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 28.952410459518433\n",
      "Train Avg Loss: 3.499010588441576\n",
      "Validation Loss: 3.4081246171678816\n",
      "Validation IoU: 0.0043909126432231955\n",
      "Validation Pixel Acc: 0.06435400960049198\n",
      "\n",
      "\n",
      "Early stop at epoch 3\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0f9f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 3.4051227058683122\n",
      "Test IoU at Test: 0.005380319448185386\n",
      "Test Pixel acc at Test: 0.06445597212099126\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673b97d",
   "metadata": {},
   "source": [
    "## Q4.c Weight Imbalance + (Image Transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a945981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassWeights():\n",
    "    ans = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    # Iterate through the training set\n",
    "    for iter, (inputs, labels) in enumerate(train_loader):  \n",
    "        unique_elements, counts = torch.unique(labels, return_counts=True)\n",
    "        \n",
    "        # Count number of each class\n",
    "        for i in range(len(unique_elements)):\n",
    "            ans[unique_elements[i]] += counts[i]\n",
    "\n",
    "    normalized = [tensor.tolist() for tensor in ans]\n",
    "    #normalized = [num/sum(normalized) for num in normalized]\n",
    "    normalized = [1/(1-pow(0.1,num/50000)) for num in normalized]\n",
    "    return torch.tensor(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70afee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.1216, 1.1572, 1.0170, 1.1338, 1.0409, 1.0001, 1.0339, 1.0002,\n",
      "        1.0062, 1.0286, 1.0025, 1.0014, 1.0195, 1.0272, 1.0000, 1.3044, 1.5265,\n",
      "        1.0004, 1.0040, 1.0026])\n"
     ]
    }
   ],
   "source": [
    "class_weights = getClassWeights()\n",
    "print(class_weights)\n",
    "class_weights = class_weights.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47417a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = FCN_ResNet34(n_class=n_class)\n",
    "fcn_model.apply(init_weights)\n",
    "fcn_model = fcn_model.to(device)\n",
    "\n",
    "earlystop = 3\n",
    "max_model = fcn_model\n",
    "\n",
    "optimizer = torch.optim.Adam(fcn_model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "#Test Cosine Annealing Learning Rate\n",
    "iterMax = math.floor(len(train_dataset)/16)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max=iterMax, eta_min=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86fdada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish epoch 0, time elapsed 30.08182120323181\n",
      "Train Avg Loss: 2.7990044014794484\n",
      "Validation Loss: 2.7985623053142\n",
      "Validation IoU: 0.0005435082912659244\n",
      "Validation Pixel Acc: 0.008267772441007652\n",
      "\n",
      "\n",
      "Finish epoch 1, time elapsed 33.21758794784546\n",
      "Train Avg Loss: 2.709486757005964\n",
      "Validation Loss: 2.300388370241438\n",
      "Validation IoU: 0.0014613871129413602\n",
      "Validation Pixel Acc: 0.009130930553024778\n",
      "\n",
      "\n",
      "Finish epoch 2, time elapsed 26.58816695213318\n",
      "Train Avg Loss: 2.562353809674581\n",
      "Validation Loss: 1.9935259478432792\n",
      "Validation IoU: 0.055795378438222146\n",
      "Validation Pixel Acc: 0.7515917897571976\n",
      "\n",
      "\n",
      "Finish epoch 3, time elapsed 28.221797227859497\n",
      "Train Avg Loss: 2.430846535733768\n",
      "Validation Loss: 1.7209132313728333\n",
      "Validation IoU: 0.048834528824204484\n",
      "Validation Pixel Acc: 0.7424669449252915\n",
      "\n",
      "\n",
      "Finish epoch 4, time elapsed 28.19951868057251\n",
      "Train Avg Loss: 2.279164915425437\n",
      "Validation Loss: 1.5418122070176261\n",
      "Validation IoU: 0.04855868898169841\n",
      "Validation Pixel Acc: 0.7448361766581632\n",
      "\n",
      "\n",
      "Finish epoch 5, time elapsed 36.76425337791443\n",
      "Train Avg Loss: 2.138098814657756\n",
      "Validation Loss: 1.3850620644433158\n",
      "Validation IoU: 0.04064916751949444\n",
      "Validation Pixel Acc: 0.7478068627004374\n",
      "\n",
      "\n",
      "Early stop at epoch 5\n"
     ]
    }
   ],
   "source": [
    "train1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14daff91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss at Test: 1.459080423627581\n",
      "Test IoU at Test: 0.04730005490900689\n",
      "Test Pixel acc at Test: 0.7262837490604499\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79be37a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
