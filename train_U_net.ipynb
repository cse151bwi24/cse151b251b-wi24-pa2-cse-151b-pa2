{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a71f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from U_net import *\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import gc\n",
    "import voc\n",
    "import torchvision.transforms as standard_transforms\n",
    "import util\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        torch.nn.init.normal_(m.bias.data) #xavier not applicable for biases\n",
    "        \n",
    "#TODO Get class weights\n",
    "def getClassWeights():\n",
    "    # TODO for Q4.c || Caculate the weights for the classes\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "750ceef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U_net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn9): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (deconv1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv11): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv13): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv15): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn16): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (deconv4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv17): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv18): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "target_transform = MaskToTensor()\n",
    "\n",
    "train_dataset =voc.VOC('train', transform=input_transform, target_transform=target_transform)\n",
    "val_dataset = voc.VOC('val', transform=input_transform, target_transform=target_transform)\n",
    "test_dataset = voc.VOC('test', transform=input_transform, target_transform=target_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size= 8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size= 8, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size= 8, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "n_class = 21\n",
    "\n",
    "U_net_model = U_net(n_class=n_class)\n",
    "U_net_model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad2ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "optimizer = torch.optim.Adam(U_net_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Choose an appropriate loss function from https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "U_net_model = U_net_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5198b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    Train a deep learning model using mini-batches.\n",
    "\n",
    "    - Perform forward propagation in each epoch.\n",
    "    - Compute loss and conduct backpropagation.\n",
    "    - Update model weights.\n",
    "    - Evaluate model on validation set for mIoU score.\n",
    "    - Save model state if mIoU score improves.\n",
    "    - Implement early stopping if necessary.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "\n",
    "    best_iou_score = 0.0\n",
    "    early_stopping_countdown = 5\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        ts = time.time()\n",
    "        if (early_stopping_countdown == 0):\n",
    "            break\n",
    "        for iter, (inputs, labels) in enumerate(train_loader):\n",
    "            # TODO / DONE  reset optimizer gradients\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # both inputs and labels have to reside in the same device as the model's\n",
    "            inputs =  inputs.to(device)# TODO / DONE transfer the input to the same device as the model's\n",
    "            labels =  labels.to(device) # TODO / DONE transfer the labels to the same device as the model's\n",
    "\n",
    "            outputs = U_net_model(inputs) # TODO / DONE Compute outputs. we will not need to transfer the output, it will be automatically in the same device as the model's!\n",
    "\n",
    "            loss = criterion(outputs, labels) #TODO / DONE calculate loss\n",
    "\n",
    "            loss.backward() # TODO / DONE backpropagate\n",
    "\n",
    "            optimizer.step() # TODO / DONE update the weights\n",
    "\n",
    "\n",
    "            if iter % 10 == 0:\n",
    "                print(\"epoch{}, iter{}, loss: {}\".format(epoch, iter, loss.item()))\n",
    "\n",
    "        print(\"Finish epoch {}, time elapsed {}\".format(epoch, time.time() - ts))\n",
    "\n",
    "        current_miou_score = val(epoch)\n",
    "\n",
    "        if current_miou_score > best_iou_score:\n",
    "            best_iou_score = current_miou_score\n",
    "            early_stopping_countdown = 5\n",
    "        else:\n",
    "            early_stopping_countdown -= 1\n",
    "            # save the best model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e42b4549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch):\n",
    "    \"\"\"\n",
    "    Validate the deep learning model on a validation dataset.\n",
    "\n",
    "    - Set model to evaluation mode. DONE\n",
    "    - Disable gradient calculations. DONE\n",
    "    - Iterate over validation data loader:\n",
    "        - Perform forward pass to get outputs.\n",
    "        - Compute loss and accumulate it.\n",
    "        - Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the epoch.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        epoch (int): The current epoch number.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Mean IoU score and mean loss for this validation epoch.\n",
    "    \"\"\"\n",
    "    U_net_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad(): # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Validation Set\n",
    "        for iter, (input, label) in enumerate(val_loader):\n",
    "            # label = (16, 224, 224) / batch size 16 of 244*244 masks\n",
    "            # output = (16, 21, 224, 224) / batch size 16 of 21 possible classes of 244*244 masks\n",
    "\n",
    "            # Take advantage of cuda if possible\n",
    "#             if device == \"cuda\":\n",
    "#                 input = input.cuda()\n",
    "\n",
    "            input =  input.to(device)\n",
    "            label = label.to(device)\n",
    "    \n",
    "            # Perform forward pass to get outputs.\n",
    "            output = U_net_model.forward(input)\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            # Find the prediction for each pixel\n",
    "            prediction = output.reshape(N, n_class, -1).argmax(dim=1).view(N, H, W)\n",
    "\n",
    "            # Compute loss and accumulate it.\n",
    "            \n",
    "            loss = criterion(output, label)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "            meanIOU = util.iou(prediction, label, n_class)\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label)\n",
    "            accuracy.append(acc)\n",
    "\n",
    "            \n",
    "    print(f\"Loss at epoch: {epoch} is {np.mean(losses)}\")\n",
    "    print(f\"IoU at epoch: {epoch} is {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Pixel acc at epoch: {epoch} is {np.mean(accuracy)}\")\n",
    "\n",
    "    U_net_model.train() #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n",
    "    return np.mean(mean_iou_scores)\n",
    "\n",
    "#  #TODO\n",
    "def modelTest():\n",
    "    \"\"\"\n",
    "    Test the deep learning model using a test dataset.\n",
    "\n",
    "    - Load the model with the best weights.\n",
    "    - Set the model to evaluation mode.\n",
    "    - Iterate over the test data loader:\n",
    "        - Perform forward pass and compute loss.\n",
    "        - Accumulate loss, IoU scores, and pixel accuracy.\n",
    "    - Print average loss, IoU, and pixel accuracy for the test data.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Returns:\n",
    "        None. Outputs average test metrics to the console.\n",
    "    \"\"\"\n",
    "\n",
    "    # Asssume model loaded with the best weights.\n",
    "\n",
    "    U_net_model.eval()  # Put in eval mode (disables batchnorm/dropout) !\n",
    "\n",
    "    losses = []\n",
    "    mean_iou_scores = []\n",
    "    accuracy = []\n",
    "\n",
    "    with torch.no_grad():  # we don't need to calculate the gradient in the validation/testing\n",
    "\n",
    "        # Iterate through Test Set\n",
    "        for iter, (input, label) in enumerate(test_loader):\n",
    "            # Take advantage of cuda if possible\n",
    "#             if device == \"cuda\":\n",
    "#                 input = input.cuda()\n",
    "\n",
    "            input =  input.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            # Perform forward pass to get outputs.\n",
    "            output = U_net_model.forward(input)\n",
    "            N, numClass, H, W = output.shape\n",
    "\n",
    "            # Find the prediction for each pixel\n",
    "            prediction = output.reshape(N, n_class, -1).argmax(dim=1).view(N, H, W)\n",
    "\n",
    "            # Compute loss and accumulate it.\n",
    "            loss = criterion(output, label)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Calculate and accumulate mean Intersection over Union (IoU) scores and pixel accuracy.\n",
    "            meanIOU = util.iou(prediction, label, n_class)\n",
    "            mean_iou_scores.append(meanIOU)\n",
    "\n",
    "            acc = util.pixel_acc(prediction, label)\n",
    "            accuracy.append(acc)\n",
    "\n",
    "    print(f\"Loss at Test: {np.mean(losses)}\")\n",
    "    print(f\"IoU at Test: {np.mean(mean_iou_scores)}\")\n",
    "    print(f\"Pixel acc at Test: {np.mean(accuracy)}\")\n",
    "\n",
    "    U_net_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(inputs):    \n",
    "    \"\"\"\n",
    "    Export the output of the model for given inputs.\n",
    "\n",
    "    - Set the model to evaluation mode.\n",
    "    - Load the model with the best saved weights.\n",
    "    - Perform a forward pass with the model to get output.\n",
    "    - Switch model back to training mode.\n",
    "\n",
    "    Args:\n",
    "        inputs: Input data to the model.\n",
    "\n",
    "    Returns:\n",
    "        Output from the model for the given inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    U_net_model.eval() # Put in eval mode (disables batchnorm/dropout) !\n",
    "    \n",
    "    saved_model_path = \"Fill Path To Best Model\"\n",
    "    # TODO Then Load your best model using saved_model_path\n",
    "    \n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    output_image = U_net_model(inputs)\n",
    "    \n",
    "    U_net_model.train()  #TURNING THE TRAIN MODE BACK ON TO ENABLE BATCHNORM/DROPOUT!!\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     val(0)  # show the accuracy before training\n",
    "#     train()\n",
    "#     modelTest()\n",
    "\n",
    "#     # housekeeping\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b05d0e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0, iter0, loss: 4.591097831726074\n",
      "epoch0, iter10, loss: 4.004241943359375\n",
      "epoch0, iter20, loss: 3.9730706214904785\n",
      "Finish epoch 0, time elapsed 17.33840322494507\n",
      "Loss at epoch: 0 is 11.523112508985731\n",
      "IoU at epoch: 0 is 0.01895571777798541\n",
      "Pixel acc at epoch: 0 is 0.22023224545894746\n",
      "epoch1, iter0, loss: 3.9464924335479736\n",
      "epoch1, iter10, loss: 3.737126588821411\n",
      "epoch1, iter20, loss: 3.6859307289123535\n",
      "Finish epoch 1, time elapsed 15.527998208999634\n",
      "Loss at epoch: 1 is 6.357552104526096\n",
      "IoU at epoch: 1 is 0.02756594952030718\n",
      "Pixel acc at epoch: 1 is 0.31242963656816897\n",
      "epoch2, iter0, loss: 3.3342363834381104\n",
      "epoch2, iter10, loss: 2.674720048904419\n",
      "epoch2, iter20, loss: 2.598109722137451\n",
      "Finish epoch 2, time elapsed 16.980859756469727\n",
      "Loss at epoch: 2 is 3.932156801223755\n",
      "IoU at epoch: 2 is 0.048280801465202916\n",
      "Pixel acc at epoch: 2 is 0.5864996508586073\n",
      "epoch3, iter0, loss: 2.507153034210205\n",
      "epoch3, iter10, loss: 2.1893255710601807\n",
      "epoch3, iter20, loss: 2.6438987255096436\n",
      "Finish epoch 3, time elapsed 20.57213258743286\n",
      "Loss at epoch: 3 is 3.800281520243044\n",
      "IoU at epoch: 3 is 0.04394064699778214\n",
      "Pixel acc at epoch: 3 is 0.5593633742559524\n",
      "epoch4, iter0, loss: 3.0124616622924805\n",
      "epoch4, iter10, loss: 2.5598855018615723\n",
      "epoch4, iter20, loss: 1.804996132850647\n",
      "Finish epoch 4, time elapsed 19.09540843963623\n",
      "Loss at epoch: 4 is 1.9041965802510579\n",
      "IoU at epoch: 4 is 0.07294858746744841\n",
      "Pixel acc at epoch: 4 is 0.7201864990787984\n",
      "epoch5, iter0, loss: 1.7626066207885742\n",
      "epoch5, iter10, loss: 1.613853096961975\n",
      "epoch5, iter20, loss: 1.6915801763534546\n",
      "Finish epoch 5, time elapsed 16.2545006275177\n",
      "Loss at epoch: 5 is 1.7922483329419736\n",
      "IoU at epoch: 5 is 0.06484972520754477\n",
      "Pixel acc at epoch: 5 is 0.7393209052284108\n",
      "epoch6, iter0, loss: 1.550694227218628\n",
      "epoch6, iter10, loss: 2.566566228866577\n",
      "epoch6, iter20, loss: 1.9916090965270996\n",
      "Finish epoch 6, time elapsed 23.82896900177002\n",
      "Loss at epoch: 6 is 2.054055765823082\n",
      "IoU at epoch: 6 is 0.06648250374224576\n",
      "Pixel acc at epoch: 6 is 0.6921189450172429\n",
      "epoch7, iter0, loss: 1.4043371677398682\n",
      "epoch7, iter10, loss: 1.1305803060531616\n",
      "epoch7, iter20, loss: 1.5028438568115234\n",
      "Finish epoch 7, time elapsed 21.33838152885437\n",
      "Loss at epoch: 7 is 1.3824484569055062\n",
      "IoU at epoch: 7 is 0.06818559708261705\n",
      "Pixel acc at epoch: 7 is 0.7485194891758787\n",
      "epoch8, iter0, loss: 1.1958634853363037\n",
      "epoch8, iter10, loss: 1.1086180210113525\n",
      "epoch8, iter20, loss: 1.5031845569610596\n",
      "Finish epoch 8, time elapsed 24.791518688201904\n",
      "Loss at epoch: 8 is 1.481566972202725\n",
      "IoU at epoch: 8 is 0.0732486893940897\n",
      "Pixel acc at epoch: 8 is 0.7463826220592403\n",
      "epoch9, iter0, loss: 1.2636852264404297\n",
      "epoch9, iter10, loss: 1.4172252416610718\n",
      "epoch9, iter20, loss: 1.2911101579666138\n",
      "Finish epoch 9, time elapsed 16.954177618026733\n",
      "Loss at epoch: 9 is 3.3460043757050126\n",
      "IoU at epoch: 9 is 0.05282726764038656\n",
      "Pixel acc at epoch: 9 is 0.6038684940121882\n",
      "epoch10, iter0, loss: 1.862032175064087\n",
      "epoch10, iter10, loss: 1.2210228443145752\n",
      "epoch10, iter20, loss: 0.974108874797821\n",
      "Finish epoch 10, time elapsed 15.251679420471191\n",
      "Loss at epoch: 10 is 1.2207622373545612\n",
      "IoU at epoch: 10 is 0.08058964845069903\n",
      "Pixel acc at epoch: 10 is 0.7511345618976757\n",
      "epoch11, iter0, loss: 1.0852036476135254\n",
      "epoch11, iter10, loss: 1.084695816040039\n",
      "epoch11, iter20, loss: 1.0252771377563477\n",
      "Finish epoch 11, time elapsed 21.537205696105957\n",
      "Loss at epoch: 11 is 1.2199131669821563\n",
      "IoU at epoch: 11 is 0.06415306816001902\n",
      "Pixel acc at epoch: 11 is 0.7511398580699641\n",
      "epoch12, iter0, loss: 1.1880220174789429\n",
      "epoch12, iter10, loss: 1.2155081033706665\n",
      "epoch12, iter20, loss: 1.0369312763214111\n",
      "Finish epoch 12, time elapsed 17.70266890525818\n",
      "Loss at epoch: 12 is 1.236400913309168\n",
      "IoU at epoch: 12 is 0.061563294747274934\n",
      "Pixel acc at epoch: 12 is 0.7454585783966364\n",
      "epoch13, iter0, loss: 1.3533223867416382\n",
      "epoch13, iter10, loss: 1.7828060388565063\n",
      "epoch13, iter20, loss: 1.0903346538543701\n",
      "Finish epoch 13, time elapsed 24.561042547225952\n",
      "Loss at epoch: 13 is 1.210755549095295\n",
      "IoU at epoch: 13 is 0.06499826037256974\n",
      "Pixel acc at epoch: 13 is 0.7456188660359977\n",
      "epoch14, iter0, loss: 1.0470271110534668\n",
      "epoch14, iter10, loss: 1.354597568511963\n",
      "epoch14, iter20, loss: 1.1711307764053345\n",
      "Finish epoch 14, time elapsed 23.130193948745728\n",
      "Loss at epoch: 14 is 1.2028315707489297\n",
      "IoU at epoch: 14 is 0.07538610361634114\n",
      "Pixel acc at epoch: 14 is 0.7471244183437264\n",
      "epoch15, iter0, loss: 1.2179795503616333\n",
      "epoch15, iter10, loss: 1.2807438373565674\n",
      "epoch15, iter20, loss: 1.2946726083755493\n",
      "Finish epoch 15, time elapsed 34.108168601989746\n",
      "Loss at epoch: 15 is 1.1897671377217327\n",
      "IoU at epoch: 15 is 0.07577096294232356\n",
      "Pixel acc at epoch: 15 is 0.7520069540402966\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2052aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at Test: 1.2930557904420075\n",
      "IoU at Test: 0.06955404985209086\n",
      "Pixel acc at Test: 0.7309609987658258\n"
     ]
    }
   ],
   "source": [
    "modelTest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
